{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eigenvectors   = 6\n",
    "window_len_proj  = 12 # months\n",
    "target_vol       = 0.2 # annualized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = robjects.r['readRDS']('kkn-replication-data.RDS')\n",
    "X['date'] = pd.to_datetime(X['date'], unit='D')\n",
    "\n",
    "# column names of the characteristics\n",
    "characteristics = X.columns[4:].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual program here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on estimation  20 of  636 -- #Factors:  6\n",
      "Currently on estimation  40 of  636 -- #Factors:  6\n",
      "Currently on estimation  60 of  636 -- #Factors:  6\n",
      "Currently on estimation  80 of  636 -- #Factors:  6\n",
      "Currently on estimation  100 of  636 -- #Factors:  6\n",
      "Currently on estimation  120 of  636 -- #Factors:  6\n",
      "Currently on estimation  140 of  636 -- #Factors:  6\n",
      "Currently on estimation  160 of  636 -- #Factors:  6\n",
      "Currently on estimation  180 of  636 -- #Factors:  6\n"
     ]
    }
   ],
   "source": [
    "nT = X['t'].max() - 1\n",
    "est_t = range(window_len_proj, X['t'].max(), 1)\n",
    "weight_l = []\n",
    "for t in est_t:\n",
    "    # some output\n",
    "    if (t - window_len_proj + 1) % 20 == 0:\n",
    "        print('Currently on estimation ', (t - window_len_proj + 1), 'of ', (nT - window_len_proj + 1), '-- #Factors: ', n_eigenvectors)\n",
    "\n",
    "    # this creates a balanced panel for the estimation period and also the prediction period\n",
    "    ind = list(i for i in range(t - window_len_proj + 1, t + 2, 1))\n",
    "    Y = X.loc[X['t'].isin(ind)].copy()\n",
    "    Y['keep'] = Y[['permno', 't']].groupby(['permno']).transform(lambda x: sorted(list(set(x))) == ind)\n",
    "    Y = Y[Y.keep == True]\n",
    "    Y = Y.drop(columns='keep').reset_index(drop=True)\n",
    "\n",
    "    # rank transform characteristics to [0,1]\n",
    "    Y[characteristics] = Y.groupby(['t']).transform(lambda x: (1/(len(x) + 1)) * (np.argsort(np.argsort(np.array(x), kind='mergesort'), kind='mergesort') + 1))[characteristics]\n",
    "\n",
    "    # subsetting for convenience\n",
    "    YA = Y.loc[Y['t'] == ind[len(ind) - 1]] # prediction period\n",
    "    Y = Y.loc[Y['t'] < ind[len(ind) - 1]] # restrict the estimation period to the time before the prediction period\n",
    "\n",
    "    # de-mean returns and project de-meaned returns on the characteristics\n",
    "    Y['ret_demean'] = Y[['permno', 'ret']].groupby(['permno']).transform(lambda x: x - np.mean(x))\n",
    "\n",
    "    # projection step\n",
    "    r = Y['ret_demean'].to_numpy()\n",
    "    Z = Y.loc[:, characteristics].to_numpy()\n",
    "    Z = Z - np.mean(Z, axis=0)\n",
    "    B = np.linalg.solve(np.dot(Z.transpose(), Z), np.dot(Z.transpose(), r))\n",
    "    yhat = np.dot(Z, B)\n",
    "    Y['rhat'] = yhat\n",
    "\n",
    "    # reshape return projection and return\n",
    "    R = Y.pivot_table(index=['permno'], columns='date', values='ret').reset_index().drop(columns=['permno']).to_numpy()\n",
    "    Rhat = Y.pivot_table(index=['permno'], columns='date', values='rhat').reset_index().drop(columns=['permno']).to_numpy()\n",
    "\n",
    "    # Eigendecomposition\n",
    "    RR = np.dot(Rhat, Rhat.transpose())\n",
    "    ED = eigsh(RR, k=n_eigenvectors, which='LM')\n",
    "    GB = np.flip(ED[1], axis=1)\n",
    "\n",
    "    # solve constrained LS problem\n",
    "    RB = R.mean(axis=1)\n",
    "    ZP = Y.loc[Y['t'] == ind[0], ['date', 'permno', 'ret', 'ret_demean'] + characteristics]\n",
    "    Z = ZP.loc[:, characteristics].to_numpy()\n",
    "    Z = Z - np.mean(Z)\n",
    "    E = Z - np.dot(np.dot(GB, GB.transpose()), Z)\n",
    "    theta = np.linalg.solve(np.dot(E.transpose(), E), np.dot(E.transpose(), RB))\n",
    "\n",
    "    # update characteristics\n",
    "    Z = YA[characteristics].to_numpy()\n",
    "\n",
    "    # normalize\n",
    "    Z = Z - np.mean(Z)\n",
    "\n",
    "    # G_X_Alpha\n",
    "    E = Z - np.dot(np.dot(GB, GB.transpose()).transpose(), Z)\n",
    "    GXA = np.dot(E, theta)\n",
    "\n",
    "    # scale towards a target vol\n",
    "    R_alpha = np.dot(GXA.transpose(), R)\n",
    "    sd_alpha = np.std(R_alpha, ddof=1)\n",
    "    sd_scale_factor = (target_vol / np.sqrt(12) / sd_alpha)\n",
    "    GXA = GXA * sd_scale_factor\n",
    "\n",
    "    #########################################################\n",
    "    # OUTPUT\n",
    "    #########################################################\n",
    "    oos_date = YA['date'].iloc[0]\n",
    "    weight_l.append(pd.DataFrame({'permno': YA['permno'], 'date': oos_date, 'weight': GXA}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bind\n",
    "weight_dt = pd.concat(weight_l, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ann_mean    ann_sd    sharpe\n",
      "0   0.29484  0.184194  1.600702\n"
     ]
    }
   ],
   "source": [
    "# merge portfolio weights with returns and compute portfolio returns and Sharpe\n",
    "R_alpha = pd.merge(left=X[['permno', 'date', 'ret']], right=weight_dt, how='inner', on=['permno', 'date'], sort=True)\n",
    "R_alpha_out = R_alpha.groupby(['date'], as_index=True, sort=True).apply(lambda x: pd.Series({'r_alpha':sum(x.weight * x.ret)})).reset_index()\n",
    "R_alpha_out = R_alpha_out.loc[R_alpha_out['date'].dt.year >= 1968]\n",
    "print(pd.DataFrame({'ann_mean':12 * np.mean(R_alpha_out['r_alpha']), 'ann_sd':np.sqrt(12) * np.std(R_alpha_out['r_alpha'], ddof=1), 'sharpe':np.sqrt(12) * np.mean(R_alpha_out['r_alpha']) / np.std(R_alpha_out['r_alpha'], ddof=1)}, index=[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
